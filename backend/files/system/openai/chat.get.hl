
// OpenAI chat endpoint, for having conversations using "gpt-xxx" models.
.arguments
   prompt:string
   type:string
   references:bool
   chat:bool
   recaptcha_response:string
   session:string
.description:@"OpenAI chat endpoint, for having conversations using 'gpt-xxx' models"
.type:public

// Invoking slot containing commonalities for all endpoints.
insert-before:x:../*/signal/*/.callback
   get-nodes:x:@.arguments/*
signal:magic.ai.endpoint-common
   .callback

      // Checking what type of model this is, and invoking correct slot accordingly.
      if
         strings.starts-with:x:@.arguments/*/model
            .:gpt
         .lambda

            // Invoking chat style of slot.
            add:x:./*/signal
               get-nodes:x:@.arguments/*
            signal:magic.ai.chat
            return-nodes:x:@signal/*

      else

         // Invoking chat style of slot.
         add:x:./*/signal
            get-nodes:x:@.arguments/*
         signal:magic.ai.completion
         return-nodes:x:@signal/*

/*
 * Applying some HTTP caching to avoid invoking OpenAI again with
 * the same question before some minimum amount of time has passed.
 */
response.headers.set
   Cache-Control:max-age=30

// Returning result of worker slot to caller.
return-nodes:x:@signal/*
