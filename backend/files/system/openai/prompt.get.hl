
/*
 * Asks OpenAI a question, and returns the answer to caller.
 *
 * Requires that you've already registered for an OpenAI account,
 * and that you've stored your configuration API key in your configuration
 * settings.
 */
.arguments
   query:string
   model:string
   temperature:int
   max_tokens:int
.description:Asks OpenAI a question, and returns tha answer to caller

// Making sure user has access to invoked endpoint.
auth.ticket.verify:root

// Sanity checking invocation.
validators.mandatory:x:@.arguments/*/query

/*
 * Making sure we use sane defaults in case user did never provide arguments
 * besides the prompt itself.
 */
.args
   model
   temperature
   max_tokens
config.get:"magic:openai:model"
set-value:x:@.args/*/model
   get-first-value
      get-value:x:@.arguments/*/model
      get-value:x:@config.get
      .:code-davinci-002
config.get:"magic:openai:temperature"
convert:x:-
   type:decimal
set-value:x:@.args/*/temperature
   get-first-value
      get-value:x:@.arguments/*/temperature
      get-value:x:@convert
      .:decimal:0
config.get:"magic:openai:max_tokens"
convert:x:-
   type:int
set-value:x:@.args/*/max_tokens
   get-first-value
      get-value:x:@.arguments/*/max_tokens
      get-value:x:@convert
      .:int:100

/*
 * Creating our Bearer token by reading our OpenAI
 * configuration settings.
 */
.token
set-value:x:@.token
   strings.concat
      .:"Bearer "
      config.get:"magic:openai:key"

// Creating an HTTP POST request towards OpenAI, now decorated.
http.post:"https://api.openai.com/v1/completions"
   headers
      Authorization:x:@.token
      Content-Type:application/json
   payload
      prompt:x:@.arguments/*/query
      model:x:@.args/*/model
      temperature:x:@.args/*/temperature
      max_tokens:x:@.args/*/max_tokens
      stop:" END"
   convert:true

// Sanity checking above invocation
if
   neq:x:@http.post
      .:int:200
   .lambda

      // Oops, error - Logging error and returning status 500 to caller.
      lambda2hyper:x:@http.post
      log.error:Something went wrong while invoking OpenAI
         error:x:@lambda2hyper
      throw:Something went wrong while invoking OpenAI, check your log for details
         public:bool:true
         status:500

/*
 * Applying some HTTP caching to avoid invoking OpenAI again with
 * the same question before some minimum amount of time has passed.
 */
response.headers.set
   Cache-Control:max-age=120

// Returning results returned from invocation above to caller
add:x:../*/return
   get-nodes:x:@http.post/*/content/*/choices/*
return
